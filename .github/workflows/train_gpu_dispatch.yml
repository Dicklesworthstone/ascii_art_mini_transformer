name: Train (GPU, self-hosted, dispatch)

on:
  workflow_dispatch:
    inputs:
      python_bin:
        description: "Python executable on the runner (e.g. python3, /opt/venv/bin/python)"
        required: true
        default: "python3"
      db_path:
        description: "Path to SQLite DB on the runner (must exist; CI runners don't have it)"
        required: true
        default: "data/ascii_art.db"
      preset:
        description: "Model size preset (small|medium|large)"
        required: true
        default: medium
      max_iters:
        description: "Max training iterations"
        required: true
        default: "50000"
      checkpoint_dir:
        description: "Where to write checkpoints (persistent path recommended for resume)"
        required: true
        default: "models/checkpoints/prod_medium_50k"
      resume_from:
        description: "Optional checkpoint to resume from (empty = no resume)"
        required: false
        default: ""
      export_dir:
        description: "Where to write exported safetensors (config.json + tokenizer.json)"
        required: true
        default: "models/exported/prod_medium_50k"
      quantize:
        description: "Optional weight-only quantized exports (none|int8|int4|both)"
        required: true
        default: none
      run_rust_validation:
        description: "Run Rust CLI inference using the exported model"
        required: true
        default: "true"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

permissions:
  contents: read

env:
  CARGO_TERM_COLOR: always
  PYTHONPATH: python
  PYTHONUNBUFFERED: "1"
  # Reduce accidental thread explosions on some setups (OpenBLAS/MKL).
  OMP_NUM_THREADS: "1"
  MKL_NUM_THREADS: "1"
  OPENBLAS_NUM_THREADS: "1"
  NUMEXPR_NUM_THREADS: "1"

jobs:
  train-gpu:
    name: Train + export (self-hosted GPU)
    runs-on: [self-hosted, gpu]
    timeout-minutes: 360
    steps:
      - name: Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2

      - name: Prepare run dir (kept for artifacts)
        shell: bash
        run: |
          set -euo pipefail
          TS="$(date +%Y%m%d_%H%M%S)"
          RUN_DIR="$RUNNER_TEMP/ascii_train_gpu_${TS}_${GITHUB_RUN_ID}"
          mkdir -p "$RUN_DIR"
          echo "RUN_DIR=$RUN_DIR" >> "$GITHUB_ENV"
          echo "LOG_FILE=$RUN_DIR/train_gpu_${TS}.log" >> "$GITHUB_ENV"
          echo "PYTHON_BIN=${{ github.event.inputs.python_bin }}" >> "$GITHUB_ENV"
          echo "DB_PATH=${{ github.event.inputs.db_path }}" >> "$GITHUB_ENV"
          echo "CKPT_DIR=${{ github.event.inputs.checkpoint_dir }}" >> "$GITHUB_ENV"
          echo "EXPORT_DIR=${{ github.event.inputs.export_dir }}" >> "$GITHUB_ENV"
          echo "Run dir: $RUN_DIR" >> "$GITHUB_STEP_SUMMARY"
          echo "DB path: \`${{ github.event.inputs.db_path }}\`" >> "$GITHUB_STEP_SUMMARY"
          echo "Checkpoint dir: \`${{ github.event.inputs.checkpoint_dir }}\`" >> "$GITHUB_STEP_SUMMARY"
          echo "Export dir: \`${{ github.event.inputs.export_dir }}\`" >> "$GITHUB_STEP_SUMMARY"

      - name: GPU + env snapshot
        shell: bash
        run: |
          set -euo pipefail
          {
            echo "=== Inputs ==="
            echo "preset=${{ github.event.inputs.preset }}"
            echo "max_iters=${{ github.event.inputs.max_iters }}"
            echo "quantize=${{ github.event.inputs.quantize }}"
            echo
            echo "=== nvidia-smi ==="
            if command -v nvidia-smi >/dev/null 2>&1; then
              nvidia-smi
            else
              echo "nvidia-smi not found"
            fi
            echo
            bash tests/e2e/env_snapshot.sh "$GITHUB_WORKSPACE" "${PYTHON_BIN}" || true
            echo
            "${PYTHON_BIN}" - <<'PY'
          from __future__ import annotations

          import sys

          try:
              import torch
          except Exception as exc:  # pragma: no cover
              raise SystemExit(
                  f"ERROR: failed to import torch ({exc.__class__.__name__}: {exc})"
              )

          try:
              import safetensors  # type: ignore
          except Exception as exc:  # pragma: no cover
              raise SystemExit(
                  f"ERROR: failed to import safetensors ({exc.__class__.__name__}: {exc})"
              )

          print(f"torch_version: {torch.__version__}")
          print(f"safetensors_version: {getattr(safetensors, '__version__', 'unknown')}")
          print(f"cuda_available: {torch.cuda.is_available()}")
          print(f"cuda_device_count: {torch.cuda.device_count()}")
          if torch.cuda.is_available():
              try:
                  print(f"cuda_bf16_supported: {torch.cuda.is_bf16_supported()}")
              except Exception as exc:  # pragma: no cover
                  print(f"cuda_bf16_supported: (error: {exc.__class__.__name__})")
          else:
              sys.exit(
                  "ERROR: torch.cuda.is_available() is False. "
                  "This workflow must run on a machine with a CUDA-enabled torch install."
              )
          PY
          } 2>&1 | tee -a "$LOG_FILE"

      - name: Verify DB path
        shell: bash
        run: |
          set -euo pipefail
          if [[ ! -f "$DB_PATH" ]]; then
            echo "ERROR: DB file not found: $DB_PATH" | tee -a "$LOG_FILE"
            echo "Note: `data/ascii_art.db` is not committed; copy the DB onto the runner and re-run." | tee -a "$LOG_FILE"
            exit 1
          fi
          ls -lh "$DB_PATH" 2>&1 | tee -a "$LOG_FILE"

      - name: Train (cuda)
        shell: bash
        run: |
          set -euo pipefail

          TRAIN_ARGS=(
            -m train.train
            --db-path "$DB_PATH"
            --preset "${{ github.event.inputs.preset }}"
            --device cuda
            --dtype bfloat16
            --checkpoint-dir "$CKPT_DIR"
            --max-iters "${{ github.event.inputs.max_iters }}"
            --batch-size 64
            --gradient-accumulation-steps 4
            --learning-rate 6e-4
            --warmup-iters 2000
            --lr-decay-iters "${{ github.event.inputs.max_iters }}"
            --min-lr 6e-5
            --eval-interval 500
            --eval-iters 200
            --save-interval 5000
            --log-interval 10
            --num-workers 4
          )

          if [[ -n "${{ github.event.inputs.resume_from }}" ]]; then
            TRAIN_ARGS+=(--resume-from "${{ github.event.inputs.resume_from }}")
          fi

          echo "Running: ${PYTHON_BIN} ${TRAIN_ARGS[*]}" | tee -a "$LOG_FILE"
          "${PYTHON_BIN}" "${TRAIN_ARGS[@]}" 2>&1 | tee -a "$LOG_FILE"

      - name: Export + validate
        shell: bash
        run: |
          set -euo pipefail
          FINAL_CKPT="$CKPT_DIR/final.pt"
          if [[ ! -f "$FINAL_CKPT" ]]; then
            echo "ERROR: expected checkpoint not found: $FINAL_CKPT" | tee -a "$LOG_FILE"
            exit 1
          fi

          EXPORT_ARGS=(
            -m train.export
            --checkpoint "$FINAL_CKPT"
            --output-dir "$EXPORT_DIR"
            --dtype float32
            --quantize "${{ github.event.inputs.quantize }}"
          )
          echo "Running: ${PYTHON_BIN} ${EXPORT_ARGS[*]}" | tee -a "$LOG_FILE"
          "${PYTHON_BIN}" "${EXPORT_ARGS[@]}" 2>&1 | tee -a "$LOG_FILE"

      - name: Quick Python inference smoke (optional)
        shell: bash
        run: |
          set -euo pipefail
          MODEL_PATH="$EXPORT_DIR/model.safetensors"
          if [[ ! -f "$MODEL_PATH" ]]; then
            echo "Skipping Python inference; missing: $MODEL_PATH" | tee -a "$LOG_FILE"
            exit 0
          fi
          "${PYTHON_BIN}" -m inference.cli "cat" \
            --model "$MODEL_PATH" \
            --width 80 --height 40 \
            --max-tokens 512 \
            --seed 0 2>&1 | tee -a "$LOG_FILE"

      - name: Install Rust toolchain (for validation)
        if: ${{ github.event.inputs.run_rust_validation == 'true' }}
        uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: nightly-2026-01-20

      - name: Rust cache (for validation)
        if: ${{ github.event.inputs.run_rust_validation == 'true' }}
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2.8.2
        with:
          workspaces: |
            rust/ascii-gen -> target

      - name: Rust inference validation
        if: ${{ github.event.inputs.run_rust_validation == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          MODEL_PATH="$EXPORT_DIR/model.safetensors"
          if [[ ! -f "$MODEL_PATH" ]]; then
            echo "ERROR: Rust validation missing model: $MODEL_PATH" | tee -a "$LOG_FILE"
            exit 1
          fi

          cargo run --manifest-path rust/ascii-gen/Cargo.toml -- \
            --model "$MODEL_PATH" \
            --format markdown \
            --width 80 --max-lines 50 --max-chars 4000 \
            --seed 0 \
            "cat" 2>&1 | tee -a "$LOG_FILE"

      - name: Upload training artifacts
        uses: actions/upload-artifact@bbbca2ddaa5d8feaa63e36b76fdaad77386f024f # v7.0.0
        with:
          name: train-gpu-${{ github.run_id }}
          path: |
            ${{ env.RUN_DIR }}/**
            ${{ env.EXPORT_DIR }}/config.json
            ${{ env.EXPORT_DIR }}/tokenizer.json
            ${{ env.EXPORT_DIR }}/model.safetensors
            ${{ env.EXPORT_DIR }}/model_int8.safetensors
            ${{ env.EXPORT_DIR }}/model_int4.safetensors
            ${{ env.EXPORT_DIR }}/quant_config.json
          if-no-files-found: ignore
          retention-days: 14
